{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d99fce-7c1b-4d37-9757-baea61472001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch.nn.utils import spectral_norm as SN\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed7ade8-180d-45e8-8419-57aafcefad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14684d69-de28-434a-a34d-c4b17918efbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "    celeba_dataset=datasets.CelebA(root=\"C:/Users/maddo/Downloads/COdes from Work/Working on now\",split='train',target_type='attr',transform=transform,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e37062-666e-414b-ab46-e7f4eede17a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8025024-d3fc-48b0-92be-28ca52ed6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(celeba_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87af0c-4bd2-4e9a-8080-7cb866d16b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be51f3-2be5-4e95-8bb7-610f8a2026df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63608269-c166-425d-a74e-778d8c364f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cn1=nn.ConvTranspose2d(in_channels=512,out_channels=256,stride=2,padding=1,kernel_size=4)   #256 layers 2x2\n",
    "        self.cn2=nn.ConvTranspose2d(in_channels=256,out_channels=128,stride=2,padding=1,kernel_size=4)   #128 layers 4x4\n",
    "        self.cn3=nn.ConvTranspose2d(in_channels=128,out_channels=64,stride=2,padding=1,kernel_size=4)  #200 layers 8x8\n",
    "        self.cn4=nn.ConvTranspose2d(in_channels=64,out_channels=32,stride=2,padding=1,kernel_size=4)  #200 layers 16x16\n",
    "        self.cn5=nn.ConvTranspose2d(in_channels=32,out_channels=16,stride=2,padding=1,kernel_size=4)   #256 layers 32x32\n",
    "        self.cn7=nn.ConvTranspose2d(in_channels=16,out_channels=3,stride=2,padding=1,kernel_size=4) #132 layers 128x128  output is 128\n",
    "        self.leakyrelu=nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.tan=nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        x=self.leakyrelu(self.cn1(x))\n",
    "        x=self.leakyrelu(self.cn2(x))\n",
    "        x=self.leakyrelu(self.cn3(x))\n",
    "        x=self.leakyrelu(self.cn4(x))\n",
    "        x=self.leakyrelu(self.cn5(x))\n",
    "        x=self.leakyrelu(self.cn7(x))\n",
    "        return self.tan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "643ca27e-0af8-44e0-8806-094d8f880bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            SN(nn.Conv2d(3, 64, 4, 2, 1)),   # 128x128 -> 64x64\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            SN(nn.Conv2d(64, 128, 4, 2, 1)), # 64x64 -> 32x32\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            SN(nn.Conv2d(128, 256, 4, 2, 1)),# 32x32 -> 16x16\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),# 16x16 -> 8x8\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*8*8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add262a9-74c4-460f-a5b2-a8c4ebaa7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientpenalty(critic,real,fake,lamb):\n",
    "    gp_bs=16\n",
    "    B = real.size(0)\n",
    "    if B > gp_bs:\n",
    "        idx = torch.randint(0, B, (gp_bs,), device=real.device)\n",
    "        real, fake = real[idx], fake[idx]\n",
    "    eps = torch.rand(real.size(0),1,1,1, device=real.device)\n",
    "    xhat = (eps*real + (1-eps)*fake).requires_grad_(True)\n",
    "    d = crit(xhat)\n",
    "    g = torch.autograd.grad(d, xhat, torch.ones_like(d), create_graph=True, only_inputs=True)[0]\n",
    "    gp = ((g.pow(2).sum([1,2,3]).sqrt() - 1)**2).mean() * lamb\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a9c19-4bf0-4dbe-b860-43aa395f6ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22afbb6d-d184-4587-81aa-fb005fe40559",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=generator().to('cuda')\n",
    "crit=critic().to('cuda')\n",
    "\n",
    "\n",
    "genoptim=optim.Adam(enc.parameters(),lr=5e-5,betas=(0.5,0.99))\n",
    "criticoptim=optim.Adam(crit.parameters(),lr=2e-5,betas=(0.5,0.99))\n",
    "lambd=15\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa3b87-c3e4-4d14-996a-0ab34d754f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd757cf3-afb0-4de2-9946-c0acee236690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e452b66-607a-43bc-a0fa-b900032fd2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616fe186-1c0c-47c5-9fce-7c8cf35d2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_z = torch.randn(64, 512, 2, 2, device='cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5840818-3ff0-4f1f-b1fb-519753fb8c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For epoch number 0 loss real is -226.40066528320312 , penalty is 110.5687255859375 ,loss gen is 4.0189008712768555\n",
      " For epoch number 0 loss real is -282.12701416015625 , penalty is 143.8992919921875 ,loss gen is 63.19264221191406\n",
      " For epoch number 0 loss real is -331.40472412109375 , penalty is 153.8828125 ,loss gen is 40.058494567871094\n",
      " For epoch number 0 loss real is -317.77178955078125 , penalty is 173.10862731933594 ,loss gen is -125.83039093017578\n",
      " For epoch number 0 loss real is -243.11114501953125 , penalty is 186.85858154296875 ,loss gen is 18.101943969726562\n",
      " For epoch number 0 loss real is -281.9412841796875 , penalty is 221.9528045654297 ,loss gen is 23.11279296875\n",
      " For epoch number 0 loss real is -281.5498352050781 , penalty is 400.0171813964844 ,loss gen is 110.90473937988281\n",
      " For epoch number 0 loss real is -337.5892028808594 , penalty is 168.91360473632812 ,loss gen is -13.02897834777832\n",
      " For epoch number 0 loss real is -268.5947265625 , penalty is 133.58038330078125 ,loss gen is -2.935723304748535\n"
     ]
    }
   ],
   "source": [
    "logevent=100\n",
    "for i in range(epochs):\n",
    "    step=0\n",
    "    for x,y in train_loader:\n",
    "        z=torch.randn(x.size(0),512,2,2).to('cuda')\n",
    "        \n",
    "        fake1=enc(z).detach()\n",
    "        \n",
    "        lossf=crit(fake1).mean()\n",
    "        x=x.to('cuda')\n",
    "        lossreal=crit(x).mean()\n",
    "        penal=gradientpenalty(crit,x,fake1,lambd)\n",
    "        loss_tot=lossf-lossreal+penal\n",
    "        criticoptim.zero_grad(set_to_none=True)\n",
    "        loss_tot.backward()\n",
    "        criticoptim.step()\n",
    "    \n",
    "        z2=torch.randn(x.size(0),512,2,2).to('cuda')\n",
    "        fake2=enc(z2)\n",
    "        lossg=-crit(fake2).mean()\n",
    "        genoptim.zero_grad(set_to_none=True)\n",
    "        lossg.backward()\n",
    "        genoptim.step()\n",
    "        step+=1\n",
    "        if step%logevent==0:\n",
    "            print(f\" For epoch number {i} loss real is {loss_tot} , penalty is {penal} ,loss gen is {lossg}\")\n",
    "    \n",
    "    enc.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_eval = enc(fixed_z).clamp(-1, 1)      # in [-1,1]\n",
    "        imgs = (fake_eval + 1) / 2                 # to [0,1] for saving\n",
    "        grid = make_grid(imgs, nrow=8, padding=2)\n",
    "        save_image(grid, f\"samples/epoch_{i:04d}.png\")\n",
    "    enc.train()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc7ebd-44eb-4894-938e-a909aef91342",
   "metadata": {},
   "outputs": [],
   "source": [
    "try1=torch.randn(2,512,2,2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f6ca26-c7de-41d2-b459-7e1a5cfb810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), 'encoder_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802b9f56-632e-4a4a-a939-0840fcb2f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(crit.state_dict(), 'critic_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29907e93-bff6-41b4-b654-dc21c40a30cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc9344-6a66-4c39-b9ef-c421dbecbcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
